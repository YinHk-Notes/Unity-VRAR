## XR Interaction Toolkit 2.2.0

The XR Interaction Toolkit package is a high-level, component-based, interaction system for creating VR and AR experiences. It provides a framework that makes 3D and UI interactions available from Unity input events. 


XR Interaction Toolkit contains a set of components that support the following Interaction tasks:

- Cross-platform XR controller input: Meta Quest (Oculus), OpenXR, Windows Mixed Reality, and more.
- Basic object hover, select and grab
- Haptic feedback through XR controllers
- Visual feedback (tint/line rendering) to indicate possible and active interactions
- Basic canvas UI interaction with XR controllers
- Utility for interacting with XR Origin, a VR camera rig for handling stationary and room-scale VR experiences


To use the AR interaction components in the package, you must have the AR Foundation package in your Project. The AR functionality provided by the XR Interaction Toolkit includes:

- AR gesture system to map screen touches to gesture events
- AR interactable can place virtual objects in the real world
- AR gesture interactor and interactables to translate gestures such as place, select, translate, rotate, and scale into object manipulation
- AR annotations to inform users about AR objects placed in the real world


https://docs.unity3d.com/Packages/com.unity.xr.interaction.toolkit@2.2/manual/index.html

